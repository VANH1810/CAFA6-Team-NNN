{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAFA-6 Blend GOA Negative Propagation\n",
    "\n",
    "This notebook implements ensemble blending of multiple model submissions with GOA Uniprot data and negative annotation filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:09.985776Z",
     "iopub.status.busy": "2025-11-10T23:50:09.98545Z",
     "iopub.status.idle": "2025-11-10T23:50:12.991996Z",
     "shell.execute_reply": "2025-11-10T23:50:12.990218Z",
     "shell.execute_reply.started": "2025-11-10T23:50:09.985751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:12.994956Z",
     "iopub.status.busy": "2025-11-10T23:50:12.994432Z",
     "iopub.status.idle": "2025-11-10T23:50:13.010727Z",
     "shell.execute_reply": "2025-11-10T23:50:13.009071Z",
     "shell.execute_reply.started": "2025-11-10T23:50:12.994918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_train_terms(path):\n",
    "    mapping = defaultdict(list)\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"protein\",\"go\",\"ont\"], dtype=str)\n",
    "    for _, r in tqdm(df.iterrows(), total=len(df)): \n",
    "        mapping[r.protein].append(r.go)\n",
    "    print(f\"[io] Read training annotations for {len(mapping)} proteins from {path}\")\n",
    "    return mapping\n",
    "\n",
    "def parse_obo(go_obo_path):\n",
    "    parents = defaultdict(set)\n",
    "    children = defaultdict(set)\n",
    "    \n",
    "    if not os.path.exists(go_obo_path): \n",
    "        return parents, children\n",
    "        \n",
    "    with open(go_obo_path,\"r\") as f:\n",
    "        cur_id=None\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            if line==\"[Term]\": \n",
    "                cur_id=None\n",
    "            elif line.startswith(\"id: \"): \n",
    "                cur_id=line.split(\"id: \")[1].strip()\n",
    "            elif line.startswith(\"is_a: \"):\n",
    "                pid=line.split()[1].strip()\n",
    "                if cur_id: \n",
    "                    parents[cur_id].add(pid)\n",
    "                    children[pid].add(cur_id)\n",
    "            elif line.startswith(\"relationship: part_of \"):\n",
    "                parts=line.split(); \n",
    "                if len(parts)>=3:\n",
    "                    pid=parts[2].strip()\n",
    "                    if cur_id: \n",
    "                        parents[cur_id].add(pid)\n",
    "                        children[pid].add(cur_id)\n",
    "    print(f\"[io] Parsed OBO: {len(parents)} nodes with parents\")\n",
    "    return parents, children\n",
    "\n",
    "def get_ancestors(go_id, parents):\n",
    "    ans=set()\n",
    "    stack=[go_id]\n",
    "    while stack:\n",
    "        cur=stack.pop()\n",
    "        for p in parents.get(cur,[]): \n",
    "            if p not in ans:\n",
    "                ans.add(p)\n",
    "                stack.append(p)\n",
    "    return ans\n",
    "\n",
    "def get_descendants(go_id):\n",
    "    desc = set()\n",
    "    stack = [go_id]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for child in children_map.get(cur, []):\n",
    "            if child not in desc:\n",
    "                desc.add(child)\n",
    "                stack.append(child)\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Submissions and GOA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Submission Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:13.012127Z",
     "iopub.status.busy": "2025-11-10T23:50:13.011844Z",
     "iopub.status.idle": "2025-11-10T23:50:45.18491Z",
     "shell.execute_reply": "2025-11-10T23:50:45.183598Z",
     "shell.execute_reply.started": "2025-11-10T23:50:13.012103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_terms = read_train_terms(\"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\")\n",
    "parents_map, children_map = parse_obo(\"/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GOA Uniprot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GO Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:45.186403Z",
     "iopub.status.busy": "2025-11-10T23:50:45.186093Z",
     "iopub.status.idle": "2025-11-10T23:50:48.755662Z",
     "shell.execute_reply": "2025-11-10T23:50:48.75462Z",
     "shell.execute_reply.started": "2025-11-10T23:50:45.186378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "go_annotations = pd.read_csv('/kaggle/input/protein-go-annotations/goa_uniprot_all.csv')\n",
    "go_annotations = go_annotations.drop_duplicates()\n",
    "print(f'[+] Dataset shape: {go_annotations.shape}')\n",
    "go_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:48.758434Z",
     "iopub.status.busy": "2025-11-10T23:50:48.758144Z",
     "iopub.status.idle": "2025-11-10T23:50:48.959625Z",
     "shell.execute_reply": "2025-11-10T23:50:48.958751Z",
     "shell.execute_reply.started": "2025-11-10T23:50:48.758411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "go_annotations.qualifier.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Annotation Processing\n",
    "\n",
    "Negative annotations (NOT qualifiers) indicate that a protein does NOT have a specific function.\n",
    "These annotations should be used to filter out incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:48.961006Z",
     "iopub.status.busy": "2025-11-10T23:50:48.960647Z",
     "iopub.status.idle": "2025-11-10T23:50:50.65797Z",
     "shell.execute_reply": "2025-11-10T23:50:50.656542Z",
     "shell.execute_reply.started": "2025-11-10T23:50:48.960966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"[1/3] Filtering Negative Annotations ..\")\n",
    "negative_annots = go_annotations[go_annotations['qualifier'].str.contains('NOT', na=False)]\n",
    "negative_annots = negative_annots.drop(columns=['qualifier']).drop_duplicates()\n",
    "\n",
    "print(f\"[2/3] Propagate Negative Terms ..\")\n",
    "negative_annots = negative_annots.groupby('protein_id')['go_term'].apply(list).to_dict()\n",
    "\n",
    "propagated={}\n",
    "for p in tqdm(negative_annots.keys()):\n",
    "    terms=set(negative_annots[p])\n",
    "    extra=set()\n",
    "    for t in list(terms): \n",
    "        extra |= get_descendants(t)\n",
    "    propagated[p] = sorted(terms | extra)\n",
    "        \n",
    "negative_annots = propagated\n",
    "\n",
    "print(f\"[3/3] Extract Unique Keys ..\")\n",
    "rows = [(protein_id, go_term) for protein_id, terms in negative_annots.items() for go_term in terms]\n",
    "negative_df = pd.DataFrame(rows, columns=[\"protein_id\", \"go_term\"])\n",
    "negative_df['pred_key'] = negative_df.protein_id.apply(str) + '_' + negative_df.go_term.apply(str)\n",
    "negative_keys = set(negative_df['pred_key'])\n",
    "\n",
    "del negative_df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Total unique negative protein-GO pairs: {len(negative_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:50.660412Z",
     "iopub.status.busy": "2025-11-10T23:50:50.659063Z",
     "iopub.status.idle": "2025-11-10T23:50:56.738661Z",
     "shell.execute_reply": "2025-11-10T23:50:56.737477Z",
     "shell.execute_reply.started": "2025-11-10T23:50:50.660379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"[1/4] Loading GOA Annotations ..\")\n",
    "go_annotations = pd.read_csv('/kaggle/input/protein-go-annotations/goa_uniprot_all.csv')\n",
    "\n",
    "print(f\"[2/4] Removing unwanted annotations ..\")\n",
    "go_annotations = go_annotations[~go_annotations['qualifier'].str.contains('NOT', na=False)]\n",
    "go_annotations.drop(columns=['qualifier'], inplace=True)\n",
    "go_annotations = go_annotations.drop_duplicates()\n",
    "\n",
    "print(f\"[3/4] Set Ground-Truth Score ..\")\n",
    "go_annotations['score'] = round(1.0, 3)\n",
    "\n",
    "print(f\"[4/4] Setting Key ..\")\n",
    "go_annotations['pred_key'] = go_annotations['protein_id'].astype(str) + '_' + go_annotations['go_term'].astype(str)\n",
    "go_annotations = go_annotations[~go_annotations['pred_key'].isin(negative_keys)]\n",
    "goa_pred_keys = set(go_annotations['pred_key'])\n",
    "print(f\"[+] Total unique ground truth protein-GO pairs: {len(goa_pred_keys)}\")\n",
    "print(f\"[âœ…] Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Blend Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:56.740126Z",
     "iopub.status.busy": "2025-11-10T23:50:56.739818Z",
     "iopub.status.idle": "2025-11-10T23:50:56.747589Z",
     "shell.execute_reply": "2025-11-10T23:50:56.746115Z",
     "shell.execute_reply.started": "2025-11-10T23:50:56.7401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_num_rows(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        num_rows = sum(1 for line in f)\n",
    "    return num_rows\n",
    "    \n",
    "\n",
    "def load_submission(path, chunksize=50000, num_rows=None):\n",
    "    if num_rows is None:  \n",
    "        num_rows = get_num_rows(path)\n",
    "        \n",
    "    total = int(num_rows / chunksize) + 1 \n",
    "    chunks = []\n",
    "    \n",
    "    for chunk in tqdm(pd.read_csv(path, sep='\\t', header=None, chunksize=chunksize), total=total):\n",
    "        chunk['pred_key'] = chunk[0].astype(str) + '_' + chunk[1].astype(str)\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    df.columns = ['protein_id', 'go_term', 'score', 'pred_key']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:50:56.748662Z",
     "iopub.status.busy": "2025-11-10T23:50:56.748421Z",
     "iopub.status.idle": "2025-11-10T23:54:53.9933Z",
     "shell.execute_reply": "2025-11-10T23:54:53.991734Z",
     "shell.execute_reply.started": "2025-11-10T23:50:56.748644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"[1/2] Loading 1st submission ..\")\n",
    "A = load_submission('/kaggle/input/nnn-kmer-tfidf-sgd/submission.tsv')\n",
    "A.drop(A.index[A['score'] < 0.04], inplace=True)\n",
    "A['score'] = A['score'].clip(upper=1.0)\n",
    "\n",
    "print(f\"[2/2] Loading 2nd submission ..\")\n",
    "B = load_submission('/kaggle/input/nnn-protbert-and-kmer-td-idf-fusion/submission.tsv')\n",
    "B.dropna(inplace=True)\n",
    "\n",
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOA Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge GOA Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:54:53.995118Z",
     "iopub.status.busy": "2025-11-10T23:54:53.99472Z",
     "iopub.status.idle": "2025-11-10T23:55:39.328674Z",
     "shell.execute_reply": "2025-11-10T23:55:39.327564Z",
     "shell.execute_reply.started": "2025-11-10T23:54:53.995084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"[1/4] Removing Ground-Truth from A ..\")\n",
    "A = A[~A.pred_key.isin(goa_pred_keys)]\n",
    "print(f\"[2/4] Removing Ground-Truth from B ..\")\n",
    "B = B[~B.pred_key.isin(goa_pred_keys)]\n",
    "\n",
    "print(f\"[3/4] Removing Negatives from A ..\")\n",
    "A = A[~A.pred_key.isin(negative_keys)]\n",
    "print(f\"[4/4] Removing Negatives from B ..\")\n",
    "B = B[~B.pred_key.isin(negative_keys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Annotation Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Negative Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:55:39.330134Z",
     "iopub.status.busy": "2025-11-10T23:55:39.329797Z",
     "iopub.status.idle": "2025-11-10T23:57:32.594186Z",
     "shell.execute_reply": "2025-11-10T23:57:32.593376Z",
     "shell.execute_reply.started": "2025-11-10T23:55:39.330106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"[1/3] Intersection keys ..\")\n",
    "A_keys = set(A.pred_key)\n",
    "B_keys = set(B.pred_key)\n",
    "intersect_keys = A_keys & B_keys\n",
    "\n",
    "print(f\"[2/3] Intersection ..\")\n",
    "\n",
    "# Leaderboard scores\n",
    "wa = 0.255\n",
    "wb = 0.213\n",
    "\n",
    "A_inter = A[A.pred_key.isin(intersect_keys)].copy()\n",
    "B_inter = B[B.pred_key.isin(intersect_keys)].copy()\n",
    "\n",
    "inter = A_inter.merge(\n",
    "    B_inter[['pred_key','score']],\n",
    "    on='pred_key',\n",
    "    suffixes=('_a','_b')\n",
    ")\n",
    "\n",
    "print(f\"[3/3] Weighted average sum ..\")\n",
    "inter['score'] = (inter['score_a'] * wa + inter['score_b'] * wb) / (wa + wb)\n",
    "inter.drop(columns = ['score_a', 'score_b'], inplace=True)\n",
    "print(f\"[*] Done.\")\n",
    "inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:57:32.595446Z",
     "iopub.status.busy": "2025-11-10T23:57:32.595185Z",
     "iopub.status.idle": "2025-11-10T23:59:39.927253Z",
     "shell.execute_reply": "2025-11-10T23:59:39.926257Z",
     "shell.execute_reply.started": "2025-11-10T23:57:32.595424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"[1/2] Add missing rows ..\")\n",
    "AnotB = A[~A.pred_key.isin(B_keys)]\n",
    "BnotA = B[~B.pred_key.isin(A_keys)]\n",
    "\n",
    "print(f\"[2/2] Merging ..\")\n",
    "submission = pd.concat([go_annotations, inter, AnotB, BnotA], axis=0)\n",
    "submission.drop(columns=['pred_key'], inplace=True)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Final Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T23:59:39.928718Z",
     "iopub.status.busy": "2025-11-10T23:59:39.928394Z",
     "iopub.status.idle": "2025-11-11T00:00:47.133549Z",
     "shell.execute_reply": "2025-11-11T00:00:47.132128Z",
     "shell.execute_reply.started": "2025-11-10T23:59:39.928665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f'[*] Saving submission...')\n",
    "submission.to_csv('submission.tsv',sep='\\t', index=False, header=None)\n",
    "print(f\"[*] Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T00:00:47.137384Z",
     "iopub.status.busy": "2025-11-11T00:00:47.137083Z",
     "iopub.status.idle": "2025-11-11T00:00:47.660103Z",
     "shell.execute_reply": "2025-11-11T00:00:47.658923Z",
     "shell.execute_reply.started": "2025-11-11T00:00:47.137361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!head submission.tsv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8559888,
     "sourceId": 13482672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8572953,
     "sourceId": 13502493,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8699749,
     "sourceId": 13680623,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9019410,
     "sourceId": 14151472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9019426,
     "sourceId": 14151748,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 268508255,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 269339911,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
