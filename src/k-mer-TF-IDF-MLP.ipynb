{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e120ccbc",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cacc7e4",
   "metadata": {},
   "source": [
    "# K-mer TF-IDF with MLP\n",
    "\n",
    "This notebook implements a protein function prediction model using k-mer TF-IDF features with linear classifiers (SGD/Logistic Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34678c91",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:18.498895Z",
     "iopub.status.busy": "2025-12-13T05:08:18.498538Z",
     "iopub.status.idle": "2025-12-13T05:08:21.786896Z",
     "shell.execute_reply": "2025-12-13T05:08:21.786053Z"
    },
    "papermill": {
     "duration": 3.295454,
     "end_time": "2025-12-13T05:08:21.788448",
     "exception": false,
     "start_time": "2025-12-13T05:08:18.492994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Set, Tuple, Optional\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import random\n",
    "import joblib\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdedf1ad",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3063e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.797814Z",
     "iopub.status.busy": "2025-12-13T05:08:21.797332Z",
     "iopub.status.idle": "2025-12-13T05:08:21.808052Z",
     "shell.execute_reply": "2025-12-13T05:08:21.807281Z"
    },
    "papermill": {
     "duration": 0.017044,
     "end_time": "2025-12-13T05:08:21.809430",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.792386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Centralized configuration\"\"\"\n",
    "    # Paths\n",
    "    DATA_DIR = Path(\"/kaggle/input/cafa-6-protein-function-prediction\")\n",
    "    TRAIN_DIR = DATA_DIR / \"Train\"\n",
    "    TEST_DIR = DATA_DIR / \"Test\"\n",
    "    WORK_DIR = Path(\"/kaggle/working\")\n",
    "    \n",
    "    # Data files\n",
    "    TRAIN_FASTA = TRAIN_DIR / \"train_sequences.fasta\"\n",
    "    TRAIN_TERMS = TRAIN_DIR / \"train_terms.tsv\"\n",
    "    TRAIN_TAXONOMY = TRAIN_DIR / \"train_taxonomy.tsv\"\n",
    "    GO_OBO = TRAIN_DIR / \"go-basic.obo\"\n",
    "    IA_FILE = DATA_DIR / \"IA.tsv\"\n",
    "    TEST_FASTA = TEST_DIR / \"testsuperset.fasta\"\n",
    "    SAMPLE_SUBMISSION = DATA_DIR / \"sample_submission.tsv\"\n",
    "    OUTPUT_FILE = WORK_DIR / \"submission.tsv\"\n",
    "    \n",
    "    # TF-IDF k-mer settings\n",
    "    KMER_NGRAM_RANGE = (3, 3)\n",
    "    KMER_MAX_FEATURES = 50000\n",
    "    KMER_MIN_DF = 2\n",
    "    KMER_SUBLINEAR_TF = True\n",
    "\n",
    "    MODEL_TYPE = \"sgd\"\n",
    "    \n",
    "    # SGD parameters\n",
    "    SGD_ALPHA = 2e-6\n",
    "    SGD_MAX_ITER = 30\n",
    "    SGD_TOL = 1e-3\n",
    "    SGD_N_JOBS = -1\n",
    "    \n",
    "    # Logistic Regression parameters\n",
    "    LOGREG_C = 4.0\n",
    "    LOGREG_MAX_ITER = 200\n",
    "    LOGREG_N_JOBS = -1\n",
    "\n",
    "    # Model parameters\n",
    "    RANDOM_SEED = 42\n",
    "    TOP_K_LABELS = 3000\n",
    "    HIDDEN_UNITS = [1024, 512]\n",
    "    DROPOUT = 0.5\n",
    "    LEARNING_RATE = 3e-4\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 50\n",
    "    PATIENCE = 5\n",
    "    \n",
    "    # Prediction parameters\n",
    "    TOP_K_PER_PROTEIN = 200\n",
    "    \n",
    "    THRESHOLD_SEARCH = True\n",
    "    THRESHOLD_GRID = np.concatenate([\n",
    "        np.arange(0.001, 0.051, 0.002),\n",
    "        np.arange(0.05, 0.201, 0.01)\n",
    "    ])\n",
    "        \n",
    "    # GO propagation\n",
    "    PROPAGATE_TRAIN = True\n",
    "    PROPAGATE_PRED = True\n",
    "    PROPAGATE_ITERATIONS = 3\n",
    "    SGD_N_JOBS = 4\n",
    "    \n",
    "    @classmethod\n",
    "    def set_seed(cls):\n",
    "        np.random.seed(cls.RANDOM_SEED)\n",
    "        random.seed(cls.RANDOM_SEED)\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(cls.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d15427",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157b617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.818603Z",
     "iopub.status.busy": "2025-12-13T05:08:21.818302Z",
     "iopub.status.idle": "2025-12-13T05:08:21.824792Z",
     "shell.execute_reply": "2025-12-13T05:08:21.824099Z"
    },
    "papermill": {
     "duration": 0.01275,
     "end_time": "2025-12-13T05:08:21.826103",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.813353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time, os\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    _PROC = psutil.Process(os.getpid())\n",
    "except Exception:\n",
    "    _PROC = None\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.t = time.perf_counter()\n",
    "\n",
    "    def hit(self, msg: str):\n",
    "        now = time.perf_counter()\n",
    "        dt = now - self.t\n",
    "        self.t = now\n",
    "        if _PROC is not None:\n",
    "            rss_gb = _PROC.memory_info().rss / (1024**3)\n",
    "            print(f\"[TIMER] {msg}: {dt:.2f}s | RSS={rss_gb:.2f} GB\")\n",
    "        else:\n",
    "            print(f\"[TIMER] {msg}: {dt:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae000e",
   "metadata": {},
   "source": [
    "## GO Ontology Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13e3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.835161Z",
     "iopub.status.busy": "2025-12-13T05:08:21.834868Z",
     "iopub.status.idle": "2025-12-13T05:08:21.844564Z",
     "shell.execute_reply": "2025-12-13T05:08:21.843892Z"
    },
    "papermill": {
     "duration": 0.015848,
     "end_time": "2025-12-13T05:08:21.845873",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.830025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Handle all data loading operations\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_fasta(path: Path) -> Dict[str, str]:\n",
    "        \"\"\"Read FASTA file and return dict of protein_id: sequence\"\"\"\n",
    "        sequences = {}\n",
    "        with open(path) as f:\n",
    "            protein_id = None\n",
    "            seq_parts = []\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\">\"):\n",
    "                    if protein_id:\n",
    "                        sequences[protein_id] = \"\".join(seq_parts)\n",
    "                    \n",
    "                    header = line[1:].split()[0]\n",
    "                    protein_id = header.split(\"|\")[1] if \"|\" in header else header\n",
    "                    seq_parts = []\n",
    "                else:\n",
    "                    seq_parts.append(line)\n",
    "            \n",
    "            if protein_id:\n",
    "                sequences[protein_id] = \"\".join(seq_parts)\n",
    "        \n",
    "        print(f\"Loaded {len(sequences):,} sequences from {path.name}\")\n",
    "        return sequences\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_annotations(path: Path) -> Dict[str, List[str]]:\n",
    "        \"\"\"Read protein-GO term annotations\"\"\"\n",
    "        df = pd.read_csv(path, sep=\"\\t\", header=None, \n",
    "                        names=[\"protein\", \"go_term\", \"ontology\"])\n",
    "        \n",
    "        annotations = defaultdict(list)\n",
    "        for _, row in df.iterrows():\n",
    "            annotations[row.protein].append(row.go_term)\n",
    "        \n",
    "        print(f\"Loaded annotations for {len(annotations):,} proteins\")\n",
    "        return dict(annotations)\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_ia_weights(path: Path) -> Dict[str, float]:\n",
    "        \"\"\"Read Information Accretion weights\"\"\"\n",
    "        if not path.exists():\n",
    "            print(\"Warning: IA weights file not found\")\n",
    "            return {}\n",
    "        \n",
    "        df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"go_term\", \"ia\"])\n",
    "        weights = {}\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                weights[row.go_term] = float(str(row.ia).replace(\",\", \".\"))\n",
    "            except:\n",
    "                weights[row.go_term] = 0.0\n",
    "        \n",
    "        print(f\"Loaded IA weights for {len(weights):,} GO terms\")\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f688f",
   "metadata": {},
   "source": [
    "## K-mer Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36467b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.855036Z",
     "iopub.status.busy": "2025-12-13T05:08:21.854274Z",
     "iopub.status.idle": "2025-12-13T05:08:21.865124Z",
     "shell.execute_reply": "2025-12-13T05:08:21.864394Z"
    },
    "papermill": {
     "duration": 0.016685,
     "end_time": "2025-12-13T05:08:21.866382",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.849697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GOGraph:\n",
    "    \"\"\"Handle Gene Ontology graph operations\"\"\"\n",
    "    \n",
    "    def __init__(self, obo_path: Path):\n",
    "        self.parents, self.children = self._parse_obo(obo_path)\n",
    "    \n",
    "    def _parse_obo(self, path: Path) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"Parse OBO file to extract parent-child relationships\"\"\"\n",
    "        parents = defaultdict(set)\n",
    "        children = defaultdict(set)\n",
    "        \n",
    "        if not path.exists():\n",
    "            print(\"Warning: OBO file not found\")\n",
    "            return parents, children\n",
    "        \n",
    "        with open(path) as f:\n",
    "            current_id = None\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if line == \"[Term]\":\n",
    "                    current_id = None\n",
    "                elif line.startswith(\"id: \"):\n",
    "                    current_id = line.split(\"id: \")[1]\n",
    "                elif line.startswith(\"is_a: \") and current_id:\n",
    "                    parent_id = line.split()[1]\n",
    "                    parents[current_id].add(parent_id)\n",
    "                    children[parent_id].add(current_id)\n",
    "                elif line.startswith(\"relationship: part_of \") and current_id:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 3:\n",
    "                        parent_id = parts[2]\n",
    "                        parents[current_id].add(parent_id)\n",
    "                        children[parent_id].add(current_id)\n",
    "        \n",
    "        print(f\"Parsed GO graph: {len(parents):,} terms with parents\")\n",
    "        return dict(parents), dict(children)\n",
    "    \n",
    "    def get_ancestors(self, go_term: str) -> Set[str]:\n",
    "        \"\"\"Get all ancestor terms\"\"\"\n",
    "        ancestors = set()\n",
    "        stack = [go_term]\n",
    "        \n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            for parent in self.parents.get(current, []):\n",
    "                if parent not in ancestors:\n",
    "                    ancestors.add(parent)\n",
    "                    stack.append(parent)\n",
    "        \n",
    "        return ancestors\n",
    "    \n",
    "    def propagate_labels(self, annotations: Dict[str, List[str]]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Propagate labels up the GO graph\"\"\"\n",
    "        print(\"Propagating labels up GO hierarchy...\")\n",
    "        propagated = {}\n",
    "        \n",
    "        for protein, terms in annotations.items():\n",
    "            expanded = set(terms)\n",
    "            for term in terms:\n",
    "                expanded.update(self.get_ancestors(term))\n",
    "            propagated[protein] = sorted(expanded)\n",
    "        \n",
    "        original_count = sum(len(v) for v in annotations.values())\n",
    "        new_count = sum(len(v) for v in propagated.values())\n",
    "        print(f\"  {original_count:,} -> {new_count:,} annotations\")\n",
    "        \n",
    "        return propagated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e7ac6",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa1947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.875132Z",
     "iopub.status.busy": "2025-12-13T05:08:21.874860Z",
     "iopub.status.idle": "2025-12-13T05:08:21.882272Z",
     "shell.execute_reply": "2025-12-13T05:08:21.879819Z"
    },
    "papermill": {
     "duration": 0.013614,
     "end_time": "2025-12-13T05:08:21.883803",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.870189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === SPEED FIX: cache ancestors ===\n",
    "from functools import lru_cache\n",
    "\n",
    "def _attach_cached_ancestors(go_graph: GOGraph):\n",
    "    @lru_cache(maxsize=None)\n",
    "    def ancestors_cached(term: str):\n",
    "        ancestors = set()\n",
    "        stack = [term]\n",
    "        while stack:\n",
    "            cur = stack.pop()\n",
    "            for p in go_graph.parents.get(cur, ()):\n",
    "                if p not in ancestors:\n",
    "                    ancestors.add(p)\n",
    "                    stack.append(p)\n",
    "        # trả về tuple để cache ổn định\n",
    "        return tuple(ancestors)\n",
    "\n",
    "    go_graph.get_ancestors = lambda t: set(ancestors_cached(t))  # override method\n",
    "\n",
    "# dùng sau khi tạo go_graph\n",
    "# pipeline.go_graph = GOGraph(...)\n",
    "# _attach_cached_ancestors(pipeline.go_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06a920",
   "metadata": {},
   "source": [
    "## Prediction Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcf931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.893193Z",
     "iopub.status.busy": "2025-12-13T05:08:21.892407Z",
     "iopub.status.idle": "2025-12-13T05:08:21.899512Z",
     "shell.execute_reply": "2025-12-13T05:08:21.898785Z"
    },
    "papermill": {
     "duration": 0.013389,
     "end_time": "2025-12-13T05:08:21.901018",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.887629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingHandler:\n",
    "    \"\"\"Handle protein embeddings: K-mer TF-IDF (SPARSE)\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build_kmer_tfidf(\n",
    "        sequences: List[str],\n",
    "        ngram_range: Tuple[int, int],\n",
    "        max_features: int,\n",
    "        min_df: int = 1,\n",
    "        sublinear_tf: bool = True,\n",
    "    ):\n",
    "        print(f\"Building TF-IDF ngram_range={ngram_range} (max_features={max_features}, min_df={min_df})...\")\n",
    "\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=ngram_range,\n",
    "            lowercase=False,\n",
    "            max_features=max_features,\n",
    "            min_df=min_df,\n",
    "            sublinear_tf=sublinear_tf,\n",
    "            dtype=np.float32,\n",
    "            norm=\"l2\",\n",
    "            use_idf=True,\n",
    "        )\n",
    "        X = vectorizer.fit_transform(sequences)\n",
    "        print(f\"Built TF-IDF: X={X.shape}, vocab_size={len(vectorizer.vocabulary_):,}\")\n",
    "        return X, vectorizer\n",
    "\n",
    "    @staticmethod\n",
    "    def transform_kmer_tfidf(\n",
    "        sequences: List[str],\n",
    "        vectorizer: TfidfVectorizer,\n",
    "    ):\n",
    "        X = vectorizer.transform(sequences)\n",
    "        print(f\"Transformed sequences with TF-IDF: {X.shape}\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df6b8e",
   "metadata": {},
   "source": [
    "## Submission Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f5a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.910435Z",
     "iopub.status.busy": "2025-12-13T05:08:21.910158Z",
     "iopub.status.idle": "2025-12-13T05:08:21.916383Z",
     "shell.execute_reply": "2025-12-13T05:08:21.915593Z"
    },
    "papermill": {
     "duration": 0.012471,
     "end_time": "2025-12-13T05:08:21.917565",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.905094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    \"\"\"Build sklearn linear multi-label models\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build_linear_model(config: Config):\n",
    "        if config.MODEL_TYPE == \"logreg\":\n",
    "            base = LogisticRegression(\n",
    "                C=config.LOGREG_C,\n",
    "                solver=\"saga\",\n",
    "                max_iter=config.LOGREG_MAX_ITER,\n",
    "                n_jobs=config.LOGREG_N_JOBS,\n",
    "                verbose=0,\n",
    "            )\n",
    "            model = OneVsRestClassifier(base, n_jobs=config.LOGREG_N_JOBS)\n",
    "            return model\n",
    "\n",
    "        # default: SGD\n",
    "        base = SGDClassifier(\n",
    "            loss=\"log_loss\",\n",
    "            alpha=config.SGD_ALPHA,\n",
    "            max_iter=config.SGD_MAX_ITER,\n",
    "            tol=config.SGD_TOL,\n",
    "            early_stopping=False,\n",
    "            n_iter_no_change=3,\n",
    "            validation_fraction=0.1,\n",
    "            average=True,\n",
    "        )\n",
    "        model = OneVsRestClassifier(base, n_jobs=config.SGD_N_JOBS)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e5050",
   "metadata": {},
   "source": [
    "## Main Pipeline\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aba45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.926970Z",
     "iopub.status.busy": "2025-12-13T05:08:21.926305Z",
     "iopub.status.idle": "2025-12-13T05:08:21.938749Z",
     "shell.execute_reply": "2025-12-13T05:08:21.938027Z"
    },
    "papermill": {
     "duration": 0.018651,
     "end_time": "2025-12-13T05:08:21.940037",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.921386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, ia_weights: Dict[str, float], go_terms: List[str]):\n",
    "        self.go_terms = go_terms\n",
    "        self.weights = np.array([ia_weights.get(t, 1.0) for t in go_terms], dtype=np.float32)\n",
    "\n",
    "    def _dense_bool(self, y_true):\n",
    "        if sp.issparse(y_true):\n",
    "            return y_true.astype(np.bool_).toarray()\n",
    "        return (y_true > 0.5)\n",
    "\n",
    "    def _f_from_prec_rec(self, p: float, r: float, eps: float = 1e-12) -> float:\n",
    "        return (2.0 * p * r) / (p + r + eps)\n",
    "\n",
    "    def fmax(self, y_true, y_prob: np.ndarray, thresholds: np.ndarray) -> Tuple[float, float]:\n",
    "        y_true_b = self._dense_bool(y_true)\n",
    "        best_t, best_f = 0.5, -1.0\n",
    "\n",
    "        for t in thresholds:\n",
    "            y_pred_b = (y_prob >= t)\n",
    "\n",
    "            tp = np.logical_and(y_true_b, y_pred_b).sum(axis=1).astype(np.float32)\n",
    "            fp = np.logical_and(~y_true_b, y_pred_b).sum(axis=1).astype(np.float32)\n",
    "            fn = np.logical_and(y_true_b, ~y_pred_b).sum(axis=1).astype(np.float32)\n",
    "\n",
    "            has_pred = (tp + fp) > 0\n",
    "            has_true = (tp + fn) > 0\n",
    "\n",
    "            p = (tp[has_pred] / (tp[has_pred] + fp[has_pred] + 1e-12)).mean() if has_pred.any() else 0.0\n",
    "            r = (tp[has_true] / (tp[has_true] + fn[has_true] + 1e-12)).mean() if has_true.any() else 0.0\n",
    "\n",
    "            f = self._f_from_prec_rec(float(p), float(r))\n",
    "            if f > best_f:\n",
    "                best_f, best_t = f, float(t)\n",
    "\n",
    "        return best_t, best_f\n",
    "\n",
    "    def ia_fmax(self, y_true, y_prob: np.ndarray, thresholds: np.ndarray) -> Tuple[float, float]:\n",
    "        y_true_b = self._dense_bool(y_true)\n",
    "        w = self.weights[None, :]\n",
    "\n",
    "        best_t, best_f = 0.5, -1.0\n",
    "        for t in thresholds:\n",
    "            y_pred_b = (y_prob >= t)\n",
    "\n",
    "            tp_w = (np.logical_and(y_true_b, y_pred_b) * w).sum(axis=1).astype(np.float32)\n",
    "            fp_w = (np.logical_and(~y_true_b, y_pred_b) * w).sum(axis=1).astype(np.float32)\n",
    "            fn_w = (np.logical_and(y_true_b, ~y_pred_b) * w).sum(axis=1).astype(np.float32)\n",
    "\n",
    "            has_pred = (tp_w + fp_w) > 0\n",
    "            has_true = (tp_w + fn_w) > 0\n",
    "\n",
    "            p = (tp_w[has_pred] / (tp_w[has_pred] + fp_w[has_pred] + 1e-12)).mean() if has_pred.any() else 0.0\n",
    "            r = (tp_w[has_true] / (tp_w[has_true] + fn_w[has_true] + 1e-12)).mean() if has_true.any() else 0.0\n",
    "\n",
    "            f = self._f_from_prec_rec(float(p), float(r))\n",
    "            if f > best_f:\n",
    "                best_f, best_t = f, float(t)\n",
    "\n",
    "        return best_t, best_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693c151",
   "metadata": {},
   "source": [
    "### Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26a4a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.948926Z",
     "iopub.status.busy": "2025-12-13T05:08:21.948609Z",
     "iopub.status.idle": "2025-12-13T05:08:21.956094Z",
     "shell.execute_reply": "2025-12-13T05:08:21.955215Z"
    },
    "papermill": {
     "duration": 0.013424,
     "end_time": "2025-12-13T05:08:21.957394",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.943970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PredictionPropagator:\n",
    "    \"\"\"Propagate predictions up GO hierarchy\"\"\"\n",
    "    \n",
    "    def __init__(self, go_graph: GOGraph, go_terms: List[str]):\n",
    "        self.go_terms = go_terms\n",
    "        self.term_to_idx = {t: i for i, t in enumerate(go_terms)}\n",
    "        \n",
    "        # Restrict parents to terms in our vocabulary\n",
    "        self.parents = {}\n",
    "        for term in go_terms:\n",
    "            self.parents[term] = {p for p in go_graph.parents.get(term, []) \n",
    "                                 if p in self.term_to_idx}\n",
    "    \n",
    "    def propagate(self, predictions: np.ndarray, \n",
    "                  iterations: int = 3) -> np.ndarray:\n",
    "        \"\"\"Propagate predictions iteratively\"\"\"\n",
    "        pred_copy = predictions.copy()\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            changed = False\n",
    "            \n",
    "            for child_idx, child_term in enumerate(self.go_terms):\n",
    "                child_scores = pred_copy[:, child_idx]\n",
    "                \n",
    "                for parent_term in self.parents.get(child_term, []):\n",
    "                    parent_idx = self.term_to_idx[parent_term]\n",
    "                    \n",
    "                    # Update parent where child score is higher\n",
    "                    mask = child_scores > pred_copy[:, parent_idx]\n",
    "                    if mask.any():\n",
    "                        pred_copy[mask, parent_idx] = child_scores[mask]\n",
    "                        changed = True\n",
    "            \n",
    "            if not changed:\n",
    "                break\n",
    "        \n",
    "        return pred_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf9649",
   "metadata": {},
   "source": [
    "### Train Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f6b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:21.966807Z",
     "iopub.status.busy": "2025-12-13T05:08:21.966344Z",
     "iopub.status.idle": "2025-12-13T05:08:22.075870Z",
     "shell.execute_reply": "2025-12-13T05:08:22.074996Z"
    },
    "papermill": {
     "duration": 0.116179,
     "end_time": "2025-12-13T05:08:22.077298",
     "exception": false,
     "start_time": "2025-12-13T05:08:21.961119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CAFA6Pipeline:\n",
    "    \"\"\"Main training and prediction pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        config.set_seed()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CAFA-6 PROTEIN FUNCTION PREDICTION PIPELINE\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        print(\"Loading data...\")\n",
    "        self.loader = DataLoader()\n",
    "        self.train_seqs = self.loader.read_fasta(config.TRAIN_FASTA)\n",
    "        self.test_seqs = self.loader.read_fasta(config.TEST_FASTA)\n",
    "        self.annotations = self.loader.read_annotations(config.TRAIN_TERMS)\n",
    "        self.ia_weights = self.loader.read_ia_weights(config.IA_FILE)\n",
    "        \n",
    "        print(\"\\nLoading GO ontology...\")\n",
    "        self.go_graph = GOGraph(config.GO_OBO)\n",
    "        _attach_cached_ancestors(self.go_graph)\n",
    "        \n",
    "        if config.PROPAGATE_TRAIN:\n",
    "            self.annotations = self.go_graph.propagate_labels(self.annotations)\n",
    "        \n",
    "        self._prepare_labels()\n",
    "        \n",
    "        print(\"\\nPreparing K-mer TF-IDF embeddings...\")\n",
    "        self.embedding_handler = EmbeddingHandler()\n",
    "        self.vectorizer = None  \n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        \"\"\"Prepare label matrix\"\"\"\n",
    "        print(\"\\nPreparing labels...\")\n",
    "        \n",
    "        self.train_proteins = [p for p in self.annotations.keys() \n",
    "                              if p in self.train_seqs]\n",
    "        print(f\"  {len(self.train_proteins):,} training proteins\")\n",
    "        \n",
    "        term_counts = Counter()\n",
    "        for protein in self.train_proteins:\n",
    "            term_counts.update(self.annotations[protein])\n",
    "        \n",
    "        top_terms = [t for t, _ in term_counts.most_common(self.config.TOP_K_LABELS)]\n",
    "        self.chosen_terms = set(top_terms)\n",
    "        print(f\"  Using top {len(self.chosen_terms):,} GO terms\")\n",
    "        \n",
    "        for protein in self.train_proteins:\n",
    "            self.annotations[protein] = [t for t in self.annotations[protein] \n",
    "                                        if t in self.chosen_terms]\n",
    "        \n",
    "        labels_list = [self.annotations[p] for p in self.train_proteins]\n",
    "        self.mlb = MultiLabelBinarizer(classes=sorted(self.chosen_terms), sparse_output=True)\n",
    "        self.y = self.mlb.fit_transform(labels_list)\n",
    "        \n",
    "        print(f\"  Label matrix shape: {self.y.shape}\")\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Build K-mer TF-IDF embeddings for training\"\"\"\n",
    "        print(\"\\nPreparing training data (K-mer TF-IDF)...\")\n",
    "        t = Timer()\n",
    "        \n",
    "        train_texts = [self.train_seqs[p] for p in self.train_proteins]\n",
    "        \n",
    "        self.X, self.vectorizer = self.embedding_handler.build_kmer_tfidf(\n",
    "            train_texts,\n",
    "            ngram_range=self.config.KMER_NGRAM_RANGE,\n",
    "            max_features=self.config.KMER_MAX_FEATURES,\n",
    "            min_df=self.config.KMER_MIN_DF,\n",
    "            sublinear_tf=self.config.KMER_SUBLINEAR_TF,\n",
    "        )\n",
    "        \n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            self.X, self.y, test_size=0.15, random_state=self.config.RANDOM_SEED\n",
    "        )\n",
    "        t.hit(\"TF-IDF fit_transform\")\n",
    "        \n",
    "        print(f\"  Train: {self.X_train.shape}\")\n",
    "        print(f\"  Val:   {self.X_val.shape}\")\n",
    "        \n",
    "    def build_and_train(self):\n",
    "        print(\"\\nBuilding linear model (OneVsRest)...\")\n",
    "        self.model = ModelBuilder.build_linear_model(self.config)\n",
    "        \n",
    "        t = Timer()\n",
    "        print(\"Training (sklearn)...\")\n",
    "        with joblib.parallel_backend(\"threading\"):\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        t.hit(\"model.fit\")\n",
    "        \n",
    "    def evaluate(self):\n",
    "        print(\"\\nEvaluating (Fmax sweep)...\")\n",
    "    \n",
    "        self.evaluator = Evaluator(self.ia_weights, list(self.mlb.classes_))\n",
    "    \n",
    "        y_val_prob = self.model.predict_proba(self.X_val).astype(np.float32)\n",
    "    \n",
    "        if self.config.PROPAGATE_PRED:\n",
    "            print(\"  Propagating VAL predictions...\")\n",
    "            propagator = PredictionPropagator(self.go_graph, list(self.mlb.classes_))\n",
    "            y_val_prob = propagator.propagate(y_val_prob, self.config.PROPAGATE_ITERATIONS)\n",
    "    \n",
    "        if self.config.THRESHOLD_SEARCH:\n",
    "            t_best, f_best = self.evaluator.fmax(self.y_val, y_val_prob, self.config.THRESHOLD_GRID)\n",
    "            t_best_ia, f_best_ia = self.evaluator.ia_fmax(self.y_val, y_val_prob, self.config.THRESHOLD_GRID)\n",
    "    \n",
    "            self.best_threshold = t_best\n",
    "            self.best_f1 = f_best\n",
    "            print(f\"  Best threshold (Fmax): {t_best:.4f} | Fmax: {f_best:.4f}\")\n",
    "            print(f\"  Best threshold (IA-Fmax): {t_best_ia:.4f} | IA-Fmax: {f_best_ia:.4f}\")\n",
    "        else:\n",
    "            self.best_threshold = 0.05\n",
    "            print(f\"  Using fixed threshold: {self.best_threshold:.4f}\")\n",
    "\n",
    "    def predict_and_submit(self):\n",
    "        print(\"\\nGenerating predictions (batch + streaming write)...\")\n",
    "    \n",
    "        if self.vectorizer is None:\n",
    "            raise RuntimeError(\"TF-IDF vectorizer is None. Did you call prepare_data() before predict_and_submit()?\")\n",
    "    \n",
    "        test_ids = list(self.test_seqs.keys())\n",
    "        test_texts = [self.test_seqs[p] for p in test_ids]\n",
    "    \n",
    "        propagator = None\n",
    "        if self.config.PROPAGATE_PRED:\n",
    "            propagator = PredictionPropagator(self.go_graph, list(self.mlb.classes_))\n",
    "    \n",
    "        top_k = self.config.TOP_K_PER_PROTEIN\n",
    "        batch_size = 4096\n",
    "    \n",
    "        print(f\"\\nWriting submission to {self.config.OUTPUT_FILE}...\")\n",
    "        with open(self.config.OUTPUT_FILE, \"w\") as f:\n",
    "            for start in range(0, len(test_ids), batch_size):\n",
    "                end = min(start + batch_size, len(test_ids))\n",
    "                batch_ids = test_ids[start:end]\n",
    "                batch_texts = test_texts[start:end]\n",
    "    \n",
    "                X_batch = self.embedding_handler.transform_kmer_tfidf(batch_texts, self.vectorizer)\n",
    "                y_prob = self.model.predict_proba(X_batch).astype(np.float32)\n",
    "    \n",
    "                if propagator is not None:\n",
    "                    y_prob = propagator.propagate(y_prob, self.config.PROPAGATE_ITERATIONS)\n",
    "    \n",
    "                for i, protein_id in enumerate(batch_ids):\n",
    "                    probs = y_prob[i]\n",
    "    \n",
    "                    if top_k < probs.shape[0]:\n",
    "                        idx = np.argpartition(probs, -top_k)[-top_k:]\n",
    "                        idx = idx[np.argsort(probs[idx])[::-1]]\n",
    "                    else:\n",
    "                        idx = np.argsort(probs)[::-1]\n",
    "    \n",
    "                    for j in idx:\n",
    "                        score = float(probs[j])\n",
    "                        if score > 1e-8:\n",
    "                            go_term = self.mlb.classes_[j]\n",
    "                            f.write(f\"{protein_id}\\t{go_term}\\t{score:.6f}\\n\")\n",
    "    \n",
    "        print(\"Done!\")\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        t = Timer()\n",
    "        try:\n",
    "            t.hit(\"start run()\")\n",
    "    \n",
    "            self.prepare_data()\n",
    "            t.hit(\"prepare_data() done\")\n",
    "    \n",
    "            self.build_and_train()\n",
    "            t.hit(\"build_and_train() done\")\n",
    "    \n",
    "            self.evaluate()\n",
    "            t.hit(\"evaluate() done\")\n",
    "    \n",
    "            self.predict_and_submit()\n",
    "            t.hit(\"predict_and_submit() done\")\n",
    "    \n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "            print(\"=\"*70)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6688377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T05:08:22.086340Z",
     "iopub.status.busy": "2025-12-13T05:08:22.085800Z",
     "iopub.status.idle": "2025-12-13T06:21:43.827265Z",
     "shell.execute_reply": "2025-12-13T06:21:43.826421Z"
    },
    "papermill": {
     "duration": 4401.747448,
     "end_time": "2025-12-13T06:21:43.828638",
     "exception": false,
     "start_time": "2025-12-13T05:08:22.081190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and run pipeline\n",
    "config = Config()\n",
    "pipeline = CAFA6Pipeline(config)\n",
    "pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8953533,
     "sourceId": 14066577,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8950709,
     "sourceId": 14066843,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4416.515446,
   "end_time": "2025-12-13T06:21:44.655427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-13T05:08:08.139981",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
